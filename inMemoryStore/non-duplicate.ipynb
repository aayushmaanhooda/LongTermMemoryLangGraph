{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3d9188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.store.base import BaseStore \n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "import uuid\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ca9be",
   "metadata": {},
   "source": [
    "Chatbot Creating New Memories(without Duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17aae847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) LTM store\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3843382",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_llm = init_chat_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3ef4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryItem(BaseModel):\n",
    "    text: str = Field(description=\"Atomic user memory as a short sentence\")\n",
    "    is_new: bool = Field(description=\"True if this memory is NEW ands should be stored. False if already know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf38800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryDecision(BaseModel):\n",
    "    should_write: bool = Field(description=\"Whether to store any memories\")\n",
    "    memories: List[MemoryItem] = Field(default_factory=list, description=\"Atomic user memories to store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9673cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_extractor = memory_llm.with_structured_output(MemoryDecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4bee9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_PROMPT = \"\"\"You are responsible for updating and maintaining accurate user memory.\n",
    "\n",
    "CURRENT USER DETAILS (existing memories):\n",
    "{user_details_content}\n",
    "\n",
    "\n",
    "TASK:\n",
    "- Review the user's latest message.\n",
    "- Extract user-specific info worth storing long-term (identity, stable preferences, ongoing projects/goals).\n",
    "- For each extracted item, set is_new=true ONLY if it adds NEW information compared to CURRENT USER DETAILS.\n",
    "- If it is basically the same meaning as something already present, set is_new=false.\n",
    "- Keep each memory as a short atomic sentence.\n",
    "- No speculation; only facts stated by the user.\n",
    "- If there is nothing memory-worthy, return an empty list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b43f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_creates_memory_node(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    namespace = (\"user\", user_id, \"details\")\n",
    "\n",
    "    # A) Load existing memories\n",
    "    existing_items = store.search(namespace)\n",
    "    existing_texts = [it.value.get(\"data\", \"\") for it in existing_items if it.value.get(\"data\")]\n",
    "    user_details_content = \"\\n\".join(f\"- {t}\" for t in existing_texts) if existing_texts else \"(empty)\"\n",
    "\n",
    "    # B) Latest user message\n",
    "    last_text = state[\"messages\"][-1]\n",
    "\n",
    "    # C) LLM extracts memories + marks new vs duplicate\n",
    "    decision: MemoryDecision = memory_extractor.invoke(\n",
    "        [\n",
    "            SystemMessage(content=MEMORY_PROMPT.format(user_details_content=user_details_content)),\n",
    "            {\"role\": \"user\", \"content\": f\"USER MESSAGE:\\n{last_text}\"},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # D) Store ONLY new memories\n",
    "    if decision.should_write:\n",
    "        for mem in decision.memories:\n",
    "            if mem.is_new:\n",
    "                store.put(namespace, str(uuid.uuid4()), {\"data\": mem.text})\n",
    "                return {\"messages\": [{\"role\": \"assistant\", \"content\": \"Noted.\"}]}\n",
    "            else:\n",
    "                return {\"messages\": [{\"role\": \"assistant\", \"content\": \"Memory already exist, chill\"}]}\n",
    "    else:\n",
    "        return {\"messages\": [{\"role\": \"assistant\", \"content\": \"Memory not IMP\"}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2faf31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Build graph: START -> chat -> END\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"chat\", chat_creates_memory_node)\n",
    "builder.add_edge(START, \"chat\")\n",
    "builder.add_edge(\"chat\", END)\n",
    "\n",
    "graph = builder.compile(store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92c7f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"u1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc63d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Noted.\n"
     ]
    }
   ],
   "source": [
    "r1 = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"My name is Aayushmaan\"}]}, config)\n",
    "print(\"Assistant:\", r1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e5297c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Memory not IMP\n"
     ]
    }
   ],
   "source": [
    "r1 = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"My name is Aayushmaan\"}]}, config)\n",
    "print(\"Assistant:\", r1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "648cf922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's name is Aayushmaan.\n"
     ]
    }
   ],
   "source": [
    "items = store.search((\"user\", \"u1\", \"details\"))\n",
    "\n",
    "for item in items:\n",
    "    print(item.value['data'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
