{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5ae5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import before_agent, after_agent, dynamic_prompt, ModelRequest\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain.embeddings import init_embeddings\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import uuid\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd789f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    user_name: str\n",
    "    store: BaseStore\n",
    "    memories: List[str] | None = None\n",
    "\n",
    "class MemoryItem(BaseModel):\n",
    "    text: str = Field(description=\"Atomic user memory\")\n",
    "    is_new: bool = Field(description=\"True if new, false if duplicate\")\n",
    "\n",
    "class MemoryDecision(BaseModel):\n",
    "    should_write: bool\n",
    "    memories: List[MemoryItem] = Field(default_factory=list)\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o\")\n",
    "memory_decide_llm = llm.with_structured_output(MemoryDecision)\n",
    "embedding = init_embeddings(\"openai:text-embedding-3-small\")\n",
    "store: BaseStore = InMemoryStore(index={\"embed\": embedding, \"dims\": 1536})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479b5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a helpful assistant with memory capabilities.\n",
    "If user-specific memory is available, use it to personalize \n",
    "your responses based on what you know about the user.\n",
    "\n",
    "Your goal is to provide relevant, friendly, and tailored \n",
    "assistance that reflects the user‚Äôs preferences, context, and past interactions.\n",
    "\n",
    "If the user‚Äôs name or relevant personal context is available, always personalize your responses by:\n",
    "    ‚Äì Always Address the user by name (e.g., \"Sure, Aayushmaan...\") when appropriate\n",
    "    ‚Äì Referencing known projects, tools, or preferences (e.g., \"your MCP server python based project\")\n",
    "    ‚Äì Adjusting the tone to feel friendly, natural, and directly aimed at the user\n",
    "\n",
    "Avoid generic phrasing when personalization is possible.\n",
    "\n",
    "Use personalization especially in:\n",
    "    ‚Äì Greetings and transitions\n",
    "    ‚Äì Help or guidance tailored to tools and frameworks the user uses\n",
    "    ‚Äì Follow-up messages that continue from past context\n",
    "\n",
    "Always ensure that personalization is based only on known user details and not assumed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "MEMORY_PROMPT = \"\"\"Analyze if this user message contains new, important memories to store.\n",
    "User: {user_name}\n",
    "Existing memories: {memories}\n",
    "\n",
    "Should you store new memories? Return structured decision.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134947ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dynamic_prompt\n",
    "def change_prompt(request:ModelRequest):\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE \n",
    "    memories = request.runtime.context.memories\n",
    "    if memories:\n",
    "        memories_str = \"\\n\".join([f\"- {m}\" for m in memories])\n",
    "        system_prompt += f\"\\n\\nUser's relevant memories:\\n{memories_str}\"\n",
    "        print(\"adding memory in system prompt\")\n",
    "    return system_prompt\n",
    "\n",
    "@before_agent\n",
    "def load_messages(state: AgentState, runtime: Runtime):\n",
    "    print(\"üîç Loading memories...\")\n",
    "    \n",
    "    ctx = runtime.context\n",
    "    if not ctx or not isinstance(ctx, Context):\n",
    "        print(\"Warning: No valid context\")\n",
    "        return None\n",
    "    \n",
    "    user_name = ctx.user_name\n",
    "    store = ctx.store\n",
    "    \n",
    "    # Use string namespace\n",
    "    namespace = f\"users/{user_name}/details\"\n",
    "    last_msg = state[\"messages\"][-1].content\n",
    "    \n",
    "    items = store.search(namespace, query=last_msg, limit=5)\n",
    "    \n",
    "    if items:\n",
    "        # Store retrieved memories in context\n",
    "        ctx.memories = [item.value.get(\"data\", \"\") for item in items]\n",
    "        print(f\"Found {len(items)} relevant memories\")\n",
    "    else:\n",
    "        ctx.memories = []\n",
    "    \n",
    "    return None  # No state change needed\n",
    "\n",
    "\n",
    "@after_agent\n",
    "def store_messages(state: AgentState, runtime: Runtime):\n",
    "    print(\"üíæ Storing memories...\")\n",
    "    \n",
    "    ctx = runtime.context\n",
    "    if not ctx or not isinstance(ctx, Context):\n",
    "        print(\"Warning: No valid context\")\n",
    "        return None\n",
    "    \n",
    "    user_name = ctx.user_name\n",
    "    store = ctx.store\n",
    "    \n",
    "    namespace = f\"users/{user_name}/details\"\n",
    "    \n",
    "    #Get existing memories WITHOUT context kwarg\n",
    "    existing_items = store.search(namespace, limit=10)\n",
    "    existing = \"\\n\".join(item.value.get(\"data\", \"\") for item in existing_items) if existing_items else \"(no memories)\"\n",
    "    \n",
    "    #Pass context as prompt variables, not LLM context kwarg\n",
    "    last_msg = state[\"messages\"][-2].content\n",
    "        \n",
    "    memory_prompt_text = MEMORY_PROMPT.format(\n",
    "        user_name=user_name,\n",
    "        memories=existing\n",
    "    )\n",
    "    \n",
    "    # Create a simple prompt with the formatted text\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", memory_prompt_text),\n",
    "        (\"human\", last_msg),\n",
    "    ])\n",
    "    \n",
    "    decision = memory_decide_llm.invoke(prompt.format_prompt().to_messages())\n",
    "    \n",
    "    if decision.should_write:\n",
    "        for mem in decision.memories:\n",
    "            if mem.is_new and mem.text.strip():\n",
    "                store.put(namespace, str(uuid.uuid4()), {\"data\": mem.text.strip()})\n",
    "        print(f\"Stored {len([m for m in decision.memories if m.is_new])} new memories\")\n",
    "    else:\n",
    "        print(\"Skipping memory storage\")\n",
    "    \n",
    "    return None  # Don't modify state\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccdb9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    system_prompt=SYSTEM_PROMPT_TEMPLATE,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    context_schema=Context,\n",
    "    middleware = [load_messages,store_messages,change_prompt],\n",
    "    store = store\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900a74ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading memories...\n",
      "üíæ Storing memories...\n",
      "Stored 1 new memories\n",
      "Hello, Aayushmaan! How can I assist you today? Whether it's about a project you're working on or any other queries you have, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "# Same thread_id persists history across calls\n",
    "config = {\"configurable\": {\"thread_id\": \"chat-1\"}}  # This enables checkpointing\n",
    "\n",
    "name = input(\"Please enter your name: \")\n",
    "# First message - pass context as keyword argument, not in config\n",
    "result1 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, my name is Aayushmaan\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(result1[\"messages\"][-1].content)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb5b633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading memories...\n",
      "Found 1 relevant memories\n",
      "adding memory in system prompt\n",
      "üíæ Storing memories...\n",
      "Stored 1 new memories\n",
      "That's great to hear, Aayushmaan! Formula 1 is such an exciting sport with its high-speed drama and intricate strategies. Do you have a favorite team or driver you‚Äôre rooting for this season?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result2 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"i like f1 a lot\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(result2[\"messages\"][-1].content)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d08cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"what do i like the most?\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(result2[\"messages\"][-1].content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca4efab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: First message - No memories yet\n",
      "============================================================\n",
      "üîç Loading memories...\n",
      "üíæ Storing memories...\n",
      "Stored 2 new memories\n",
      "\n",
      "Agent response:\n",
      "Hi Aayushmaan! That sounds like a fascinating project. Developing a RAG evaluation system using RAGAS must involve some intricate work with retrieval-augmented generation. How's the project coming along? If you need any specific help or information, feel free to ask!\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST 2: Second message - Should store memory from first message\n",
      "============================================================\n",
      "üîç Loading memories...\n",
      "Found 2 relevant memories\n",
      "adding memory in system prompt\n",
      "üíæ Storing memories...\n",
      "Skipping memory storage\n",
      "\n",
      "Agent response:\n",
      "For your RAG evaluation system using RAGAS, there are several frameworks that can be quite beneficial:\n",
      "\n",
      "1. **PyTorch or TensorFlow**: Both are well-suited for machine learning and deep learning tasks. You can use them to build or refine models if needed.\n",
      "\n",
      "2. **Hugging Face Transformers**: This library is perfect for working with pre-trained models and could be helpful if you're utilizing transformer models for retrieval or generation tasks.\n",
      "\n",
      "3. **FAISS**: If your system involves dense vector retrieval, FAISS is a great tool for efficient similarity search and clustering of dense vectors.\n",
      "\n",
      "4. **RAGAS Framework**: Since you're working with RAG evaluation, utilizing the specific functionalities offered by the RAGAS framework will be crucial for your project's success.\n",
      "\n",
      "5. **Scikit-learn**: For any traditional machine learning needs or data preprocessing steps, scikit-learn is essential.\n",
      "\n",
      "6. **NLTK or SpaCy**: For natural language processing tasks, such as tokenization or named entity recognition, these libraries can be quite helpful.\n",
      "\n",
      "Each of these has its strengths, so it might depend on the specific components of your project that you're focusing on. If you have more specific requirements or constraints, let me know, and I might be able to give more tailored advice!\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST 3: Related question - Should retrieve RAG memory\n",
      "============================================================\n",
      "üîç Loading memories...\n",
      "Found 2 relevant memories\n",
      "adding memory in system prompt\n",
      "üíæ Storing memories...\n",
      "Skipping memory storage\n",
      "\n",
      "Agent response:\n",
      "Evaluating Retrieval-Augmented Generation (RAG) systems can be quite intricate due to the combination of retrieval and generation components. Here are some approaches you might find useful:\n",
      "\n",
      "1. **Retrieval Evaluation**:\n",
      "   - **Precision and Recall**: Measure how effectively the retrieval component finds relevant documents. High precision ensures the retrieved documents are relevant, while high recall ensures all relevant documents are retrieved.\n",
      "   - **Mean Reciprocal Rank (MRR)**: Useful for evaluating the rank of the first correct document.\n",
      "   - **Normalized Discounted Cumulative Gain (NDCG)**: Takes into account the position of relevant documents in the ranked list.\n",
      "\n",
      "2. **Generation Evaluation**:\n",
      "   - **BLEU, ROUGE, and METEOR Scores**: These are traditional metrics used to evaluate the overlap of the generated text with reference text.\n",
      "   - **BERTScore**: Measures semantic similarity by using BERT embeddings, which can be more robust than traditional n-gram overlap methods.\n",
      "   - **Human Evaluation**: Sometimes human judgment on fluency, relevance, and coherence is necessary, especially if automatic metrics don't tell the whole story.\n",
      "\n",
      "3. **End-to-End Evaluation**:\n",
      "   - **Task Success Rate**: Depending on the application, you could measure the end-to-end task completion rate or correctness.\n",
      "   - **User Satisfaction**: Surveys or feedback loops if the RAG system is user-facing can provide valuable qualitative data.\n",
      "\n",
      "4. **Using RAGAS**:\n",
      "   - Since you‚Äôre working with RAGAS for evaluation, make sure to leverage any built-in capabilities it offers to measure how well your RAG system performs in terms of retrieval and generation together. This might include advanced metrics or analysis tools specific to retrieval-augmented setups.\n",
      "\n",
      "Each of these methods can provide a different perspective on the performance of your RAG system. Combining them will give you a more comprehensive evaluation. If you need more specific guidance on implementing any of these evaluation methods, feel free to ask!\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST 4: New context - Add more memories\n",
      "============================================================\n",
      "üîç Loading memories...\n",
      "Found 2 relevant memories\n",
      "adding memory in system prompt\n",
      "üíæ Storing memories...\n",
      "Stored 2 new memories\n",
      "\n",
      "Agent response:\n",
      "That's great, Aayushmaan! Using LangGraph for multi-agent systems sounds intriguing, especially when combined with your work on RAG systems. As you prepare for AI engineering interviews, here are some tips that might help you:\n",
      "\n",
      "1. **Technical Foundations**:\n",
      "   - Brush up on your understanding of machine learning fundamentals, data structures, and algorithms, as these areas are often probed in interviews.\n",
      "   - Be ready to explain how you've used frameworks like RAGAS and LangGraph in your projects.\n",
      "\n",
      "2. **Project Experience**:\n",
      "   - Be prepared to discuss your RAG evaluation system in detail. Explain the challenges you faced, the solutions you implemented, and the results you achieved.\n",
      "   - Highlight your work with multi-agent systems using LangGraph, focusing on any unique aspects or innovations you contributed to the projects.\n",
      "\n",
      "3. **Problem-Solving**:\n",
      "   - Practice coding problems on platforms like LeetCode or HackerRank to stay sharp on your problem-solving skills.\n",
      "   - Consider scenarios where you might need to optimize or troubleshoot a RAG or multi-agent system, and practice explaining your thought process.\n",
      "\n",
      "4. **AI/ML Trends and Ethics**:\n",
      "   - Stay informed about the latest trends and ethical considerations in AI and machine learning. This could help you in discussions during interviews.\n",
      "\n",
      "5. **Soft Skills**:\n",
      "   - Be ready to demonstrate your communication skills, particularly how you explain complex technical concepts to non-technical stakeholders.\n",
      "\n",
      "If you need specific resources or further assistance with interview preparation, just let me know. Good luck with your interview prep!\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST 5: Related to new memory - Should use LangGraph memory\n",
      "============================================================\n",
      "üîç Loading memories...\n",
      "Found 4 relevant memories\n",
      "adding memory in system prompt\n",
      "üíæ Storing memories...\n",
      "Skipping memory storage\n",
      "\n",
      "Agent response:\n",
      "When working with LangGraph for multi-agent systems, there are a few best practices that can enhance your development process and improve system performance:\n",
      "\n",
      "1. **Modular Design**:\n",
      "   - Design your agents to be modular, allowing you to easily plug-and-play different components as needed. This can help with flexibility and scalability.\n",
      "\n",
      "2. **Clear Communication Protocols**:\n",
      "   - Define clear communication protocols between agents. Ensure that messages are consistent, and handle errors gracefully to maintain robust interactions.\n",
      "\n",
      "3. **Efficient State Management**:\n",
      "   - Manage the state of each agent efficiently. Use appropriate data structures and consider the lifecycle of your states, especially in dynamic environments.\n",
      "\n",
      "4. **Testing Framework**:\n",
      "   - Implement a comprehensive testing framework to simulate various scenarios and ensure the agents perform as expected under different conditions.\n",
      "\n",
      "5. **Use Visualization Tools**:\n",
      "   - When possible, use visualization tools to see how your agents interact and identify potential bottlenecks or errors in their interactions.\n",
      "\n",
      "6. **Performance Monitoring**:\n",
      "   - Regularly monitor the performance of your system to identify and address any performance bottlenecks. Profiling tools can be invaluable for this purpose.\n",
      "\n",
      "7. **Iterative Development**:\n",
      "   - Adopt an iterative approach to development. Start with a basic version of your system and gradually build complexity, testing as you go.\n",
      "\n",
      "8. **Documentation**:\n",
      "   - Maintain thorough documentation of your agent designs, communication protocols, and any custom modules. This aids in both development and debugging.\n",
      "\n",
      "By following these best practices, you can create more efficient and robust multi-agent systems using LangGraph. If there's anything specific you want to expand upon or need further assistance with, just let me know!\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST 6: Unrelated question - Minimal memory retrieval\n",
      "============================================================\n",
      "üîç Loading memories...\n",
      "Found 4 relevant memories\n",
      "adding memory in system prompt\n",
      "üíæ Storing memories...\n",
      "Skipping memory storage\n",
      "\n",
      "Agent response:\n",
      "I'm unable to provide real-time weather updates. To get the current weather conditions, I recommend checking a weather app or website with up-to-date information for your location. If you're planning something specific, let me know if I can help with any other details!\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST 7: Interview prep question - Should use interview memory\n",
      "============================================================\n",
      "üîç Loading memories...\n",
      "Found 4 relevant memories\n",
      "adding memory in system prompt\n",
      "üíæ Storing memories...\n",
      "Skipping memory storage\n",
      "\n",
      "Agent response:\n",
      "Preparing for AI engineering interviews can be quite comprehensive. Here‚Äôs a tailored guide for you, Aayushmaan:\n",
      "\n",
      "1. **Core Concepts and Theory**:\n",
      "   - Make sure you have a solid understanding of machine learning fundamentals, including different types of algorithms (supervised, unsupervised, reinforcement learning).\n",
      "   - Understand key concepts like overfitting, underfitting, bias-variance tradeoff, and model evaluation metrics.\n",
      "\n",
      "2. **Technical Skills**:\n",
      "   - Review your knowledge of Python and libraries like NumPy, pandas, PyTorch, TensorFlow, and scikit-learn.\n",
      "   - Be comfortable with data preprocessing, feature engineering, and model tuning.\n",
      "\n",
      "3. **Your Projects**:\n",
      "   - Be ready to discuss your RAG evaluation system and your use of LangGraph for multi-agent systems in detail. Highlight challenges you faced, solutions you crafted, and the impact of your work.\n",
      "   - Prepare to showcase any unique or innovative approaches you took in your projects.\n",
      "\n",
      "4. **Coding and Algorithms**:\n",
      "   - Practice coding questions, especially related to data structures and algorithms, on platforms like LeetCode or HackerRank.\n",
      "   - Focus on problem-solving strategies and optimizing solution complexities.\n",
      "\n",
      "5. **System Design**:\n",
      "   - Understand the basics of designing scalable and robust AI systems. This can include data pipelines, model deployment, and monitoring.\n",
      "\n",
      "6. **Stay Updated**:\n",
      "   - Familiarize yourself with the latest trends and advancements in AI and machine learning. Journals, blogs, and conferences can be good sources.\n",
      "\n",
      "7. **Behavioral Interview Prep**:\n",
      "   - Prepare to discuss your experiences and responses to challenges, teamwork, and your growth as an AI engineer.\n",
      "\n",
      "8. **Mock Interviews**:\n",
      "   - Conduct mock interviews to simulate the interview setting. This can help reduce anxiety and improve your confidence.\n",
      "\n",
      "If you need resources or specific assistance in any of these areas, just let me know. Best of luck with your preparation, Aayushmaan!\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST 8: Different user - No shared memories\n",
      "============================================================\n",
      "üîç Loading memories...\n",
      "üíæ Storing memories...\n",
      "Stored 1 new memories\n",
      "\n",
      "Agent response:\n",
      "Hi there! It's great to hear you're working on web development. Are you working on a specific project or tool at the moment? If you need any help or tips, feel free to let me know!\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST 9: Back to original user - Should still have old memories\n",
      "============================================================\n",
      "üîç Loading memories...\n",
      "Found 4 relevant memories\n",
      "adding memory in system prompt\n",
      "üíæ Storing memories...\n",
      "Skipping memory storage\n",
      "\n",
      "Agent response:\n",
      "You're working on a RAG evaluation system using RAGAS and utilizing LangGraph for multi-agent systems. If you have any updates or need assistance with either project, feel free to share!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Test config - same thread_id persists history\n",
    "config = {\"configurable\": {\"thread_id\": \"chat-1\"}}\n",
    "\n",
    "name = \"Aayushmaan\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: First message - No memories yet\")\n",
    "print(\"=\" * 60)\n",
    "result1 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, my name is Aayushmaan. I'm working on a RAG evaluation system using RAGAS.\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(\"\\nAgent response:\")\n",
    "print(result1[\"messages\"][-1].content)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Second message - Should store memory from first message\")\n",
    "print(\"=\" * 60)\n",
    "result2 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What frameworks should I use for my project?\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(\"\\nAgent response:\")\n",
    "print(result2[\"messages\"][-1].content)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Related question - Should retrieve RAG memory\")\n",
    "print(\"=\" * 60)\n",
    "result3 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"How do I evaluate RAG systems?\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(\"\\nAgent response:\")\n",
    "print(result3[\"messages\"][-1].content)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 4: New context - Add more memories\")\n",
    "print(\"=\" * 60)\n",
    "result4 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"I also use LangGraph for multi-agent systems and I'm preparing for AI engineering interviews.\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(\"\\nAgent response:\")\n",
    "print(result4[\"messages\"][-1].content)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 5: Related to new memory - Should use LangGraph memory\")\n",
    "print(\"=\" * 60)\n",
    "result5 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What are best practices for LangGraph?\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(\"\\nAgent response:\")\n",
    "print(result5[\"messages\"][-1].content)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 6: Unrelated question - Minimal memory retrieval\")\n",
    "print(\"=\" * 60)\n",
    "result6 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's the weather like?\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(\"\\nAgent response:\")\n",
    "print(result6[\"messages\"][-1].content)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 7: Interview prep question - Should use interview memory\")\n",
    "print(\"=\" * 60)\n",
    "result7 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"How should I prepare for AI engineering interviews?\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(\"\\nAgent response:\")\n",
    "print(result7[\"messages\"][-1].content)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 8: Different user - No shared memories\")\n",
    "print(\"=\" * 60)\n",
    "other_name = \"John\"\n",
    "result8 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, I'm working on web development\")]\n",
    "}, {\"configurable\": {\"thread_id\": \"chat-2\"}}, context=Context(user_name=other_name, store=store))\n",
    "\n",
    "print(\"\\nAgent response:\")\n",
    "print(result8[\"messages\"][-1].content)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 9: Back to original user - Should still have old memories\")\n",
    "print(\"=\" * 60)\n",
    "result9 = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Remind me what I'm working on\")]\n",
    "}, config, context=Context(user_name=name, store=store))\n",
    "\n",
    "print(\"\\nAgent response:\")\n",
    "print(result9[\"messages\"][-1].content)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8e7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
